{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "web_scraping_2.py",
      "authorship_tag": "ABX9TyNC4awESmuaWoDUiR43Xy7n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rahulshinde5/Web-Scraping-Assignment-/blob/main/web_scraping_2_py.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5tlppKtj5K_N"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "# 1. World Bank Evaluation and Ratings\n",
        "df10page = pd.DataFrame(columns=['Organisation Name', 'Lessons'])\n",
        "\n",
        "for page in range(1, 5):\n",
        "    html_txt = requests.get('https://ieg.worldbankgroup.org/data')\n",
        "    soup = BeautifulSoup(html_txt.text, 'lxml')\n",
        "    organisations = soup.find_all(\"tr\")\n",
        "\n",
        "    for organisation in organisations:\n",
        "        organisation_name = organisation.find('h3').text.strip()\n",
        "        lessons = organisation.find('p').text.strip()\n",
        "\n",
        "        df10page = pd.concat([df10page, pd.DataFrame({'Organisation Name': [organisation_name], 'Lessons': [lessons]})], ignore_index=True)\n",
        "        df10page = df10page.dropna(axis=1, how='all')\n",
        "\n",
        "# 2. China International Tendoring\n",
        "df11page = pd.DataFrame(columns=['Date', 'New Tender', 'Change tender', 'Evaluation Result', 'Tender Awards'])\n",
        "\n",
        "for page in range(1, 15):\n",
        "    html_txt = requests.get('http://en.chinabidding.mofcom.gov.cn')\n",
        "    soup = BeautifulSoup(html_txt.text, 'lxml')\n",
        "    c1 = soup.find_all('div', class_=\"w360 h286 fr\")\n",
        "    c2 = soup.find_all('div', class_=\"w360 h286 fl\")\n",
        "    c3 = soup.find_all('div', class_=\"news-item fl\")\n",
        "    c4 = soup.find_all('div', class_=\"news-item fr\")\n",
        "\n",
        "    for a in c1:\n",
        "        date = a.find('span', class_=\"fr\").text.strip()\n",
        "        new_tender = a.find('a', class_=\"fl\").text.strip()\n",
        "\n",
        "    for b in c2:\n",
        "        change_tender = b.find('a', class_=\"fl\").text.strip()\n",
        "\n",
        "    for c in c3:\n",
        "        evaluation_result = c.find('a', class_=\"fl\").text.strip()\n",
        "\n",
        "    for d in c4:\n",
        "        tender_award = d.find('a', class_=\"fl\").text.strip()\n",
        "\n",
        "        df11page = pd.concat(\n",
        "            [df11page, pd.DataFrame({'Date': [date], 'New Tender': [new_tender], 'Change tender': [change_tender],\n",
        "                                     'Evaluation Result': [evaluation_result], 'Tender Award': [tender_award]})],\n",
        "            ignore_index=True)\n",
        "\n",
        "df11page = df11page.dropna(axis=1, how='all')\n",
        "\n",
        "# 3. China Projects\n",
        "data_list = []\n",
        "\n",
        "for page in range(1, 10):\n",
        "    url = 'https://www.cpppc.org/en/PPPyd.jhtml?page=1'\n",
        "    html_txt = requests.get(url)\n",
        "    soup = BeautifulSoup(html_txt.text, 'lxml')\n",
        "    project_name = soup.find_all('li')\n",
        "\n",
        "    for j in project_name:\n",
        "        title = j.find('a', class_='content-title')\n",
        "        description = j.find('div', class_='content-content')\n",
        "\n",
        "        if title and description:\n",
        "            title_text = title.text.strip()\n",
        "            description_text = description.text.strip()\n",
        "            data_list.append({'Title': title_text, 'Description': description_text})\n",
        "\n",
        "df12page = pd.DataFrame(data_list)\n",
        "\n",
        "# 4. Government eProcurement System\n",
        "data_list1 = []\n",
        "\n",
        "for page in range(1, 10):\n",
        "    url = 'https://etenders.gov.in/eprocure/app'\n",
        "    html_txt = requests.get(url)\n",
        "    soup = BeautifulSoup(html_txt.text, 'lxml')\n",
        "    even_rows = soup.find_all('tr', class_='even')\n",
        "\n",
        "    for i in even_rows:\n",
        "        tender_title_elem = i.find('td', width='30%')\n",
        "        reference_number_elem = i.find('td', width='20%')\n",
        "        closing_date_elem = i.find('td', width='25%')\n",
        "\n",
        "        if tender_title_elem and reference_number_elem and closing_date_elem:\n",
        "            tender_title = tender_title_elem.text.strip()\n",
        "            reference_number = reference_number_elem.text.strip()\n",
        "            closing_date = closing_date_elem.text.strip()\n",
        "\n",
        "            data_list1.append({'Tender Title': tender_title, 'Reference Number': reference_number, 'Closing Date': closing_date})\n",
        "\n",
        "    odd_rows = soup.find_all('tr', class_='odd')\n",
        "    for j in odd_rows:\n",
        "        tender_title_elem = j.find('td', width='30%')\n",
        "        reference_number_elem = j.find('td', width='20%')\n",
        "        closing_date_elem = j.find('td', width='25%')\n",
        "\n",
        "        if tender_title_elem and reference_number_elem and closing_date_elem:\n",
        "            tender_title = tender_title_elem.text.strip()\n",
        "            reference_number = reference_number_elem.text.strip()\n",
        "            closing_date = closing_date_elem.text.strip()\n",
        "\n",
        "            data_list1.append({'Tender Title': tender_title, 'Reference Number': reference_number, 'Closing Date': closing_date})\n",
        "\n",
        "df13page = pd.DataFrame(data_list1)\n",
        "\n",
        "# Display the DataFrames\n",
        "print(\"1. World Bank Evaluation and Ratings\")\n",
        "print(df10page.head(5))\n",
        "print(\"\\n2. China International Tendoring\")\n",
        "print(df11page)\n",
        "print(\"\\n3. China Projects\")\n",
        "print(df12page)\n",
        "print(\"\\n4. Government eProcurement System\")\n",
        "print(df13page)\n"
      ]
    }
  ]
}